{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating synthetic training data for yolov5 model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "# Install yolov5 and its requirements, as well as our project's dependencies\n",
    "![ ! -d \"yolov5\" ] && git clone https://github.com/ultralytics/yolov5\n",
    "![ -d \"yolov5\" ] && cd yolov5 && git pull\n",
    "!cd yolov5 && pip install -qr requirements.txt\n",
    "!pip install -qr requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf background_images\n",
    "#!unzip \"bg-*\".zip -d background_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import *\n",
    "from skimage import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "from math import floor\n",
    "from random import shuffle, randint\n",
    "from itertools import combinations\n",
    "from iteration_utilities import grouper\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import hashlib\n",
    "import os\n",
    "import io\n",
    "import shutil\n",
    "import glob\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://stackoverflow.com/questions/40895785/using-opencv-to-overlay-transparent-image-onto-another-image\n",
    "def add_transparent_image(background, foreground, x_offset=None, y_offset=None):\n",
    "    bg_h, bg_w, bg_channels = background.shape\n",
    "    fg_h, fg_w, fg_channels = foreground.shape\n",
    "\n",
    "    assert bg_channels == 3, f'background image should have exactly 3 channels (RGB). found:{bg_channels}'\n",
    "    assert fg_channels == 4, f'foreground image should have exactly 4 channels (RGBA). found:{fg_channels}'\n",
    "\n",
    "    # center by default\n",
    "    if x_offset is None: x_offset = (bg_w - fg_w) // 2\n",
    "    if y_offset is None: y_offset = (bg_h - fg_h) // 2\n",
    "\n",
    "    w = min(fg_w, bg_w, fg_w + x_offset, bg_w - x_offset)\n",
    "    h = min(fg_h, bg_h, fg_h + y_offset, bg_h - y_offset)\n",
    "\n",
    "    if w < 1 or h < 1: return\n",
    "\n",
    "    # clip foreground and background images to the overlapping regions\n",
    "    bg_x = max(0, x_offset)\n",
    "    bg_y = max(0, y_offset)\n",
    "    fg_x = max(0, x_offset * -1)\n",
    "    fg_y = max(0, y_offset * -1)\n",
    "    foreground = foreground[fg_y:fg_y + h, fg_x:fg_x + w]\n",
    "    background_subsection = background[bg_y:bg_y + h, bg_x:bg_x + w]\n",
    "\n",
    "    # separate alpha and color channels from the foreground image\n",
    "    foreground_colors = foreground[:, :, :3]\n",
    "    alpha_channel = foreground[:, :, 3] / 255  # 0-255 => 0.0-1.0\n",
    "\n",
    "    # construct an alpha_mask that matches the image shape\n",
    "    alpha_mask = np.dstack((alpha_channel, alpha_channel, alpha_channel))\n",
    "\n",
    "    # combine the background with the overlay image weighted by alpha\n",
    "    composite = background_subsection * (1 - alpha_mask) + foreground_colors * alpha_mask\n",
    "\n",
    "    # overwrite the section of the background image that has been updated\n",
    "    background[bg_y:bg_y + h, bg_x:bg_x + w] = composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Item = namedtuple(\"Item\", 'w h color')\n",
    "Rectangle = namedtuple(\"Rectangle\", \"x y w h\")\n",
    "Border = namedtuple(\"Border\", \"w h\")\n",
    "Canvas = namedtuple(\"Canvas\", \"width height\")\n",
    "\n",
    "def overlap(rects):\n",
    "    for rectA, rectB in list(combinations(rects, 2)):\n",
    "        rectA_x2 = rectA.x + rectA.w\n",
    "        rectA_y2 = rectA.y + rectA.h\n",
    "        rectB_x2 = rectB.x + rectB.w\n",
    "        rectB_y2 = rectB.y + rectB.h\n",
    "        if rectA.x <= rectB_x2 and rectA_x2 >= rectB.x and rectA.y <= rectB_y2 and rectA_y2 >= rectB.y:\n",
    "            print(f'A.x1 = {rectA.x}, A.x2 = {rectA_x2} / B.x1 = {rectB.x}, B.x2 = {rectB_x2}')\n",
    "            print(f'A.y1 = {rectA.y}, A.y2 = {rectA_y2} / B.y1 = {rectB.y}, B.y2 = {rectB_y2}')\n",
    "            return True\n",
    "    return False\n",
    "def out_of_area(canvas, rects):\n",
    "    for rect in rects:\n",
    "        if rect.x < 0 or (rect.x + rect.w) > canvas.width or rect.y > canvas.height or rect.y < 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def draw_items(background, labels, items, border):\n",
    "    rects = []\n",
    "    label = io.StringIO()\n",
    "    max_h = max(items, key=lambda item: item[1].shape[0])[1].shape[0] + border.h\n",
    "    max_w = max(items, key=lambda item: item[1].shape[1])[1].shape[1] + border.w  \n",
    "    canvas = Canvas(height=background.shape[0], width=background.shape[1])\n",
    "    # max_squares = min(floor(canvas.width / max_w), floor(canvas.height / max_h))\n",
    "    max_squares = floor(canvas.width / max_w) * floor(canvas.height / max_h)\n",
    "    assert(len(items) <= max_squares)\n",
    "    grids = list(range(max_squares))\n",
    "    shuffle(grids)\n",
    "    for item in items:\n",
    "        # canvas.fill_style = item.color\n",
    "        pos = grids.pop()\n",
    "        # item_x = (pos * max_w) + randint(0, max_w - item.w)\n",
    "        item_x = (pos % floor(canvas.width / max_w) * max_w)\n",
    "        item_x = randint(item_x, item_x + max_w - item[1].shape[1] - border.w)\n",
    "        item_y = floor(pos / floor(canvas.width / max_w)) * max_h\n",
    "        # print(f'before: item_y = {item_y}, pos = {pos}')\n",
    "        item_y = randint(item_y, item_y + max_h - item[1].shape[0] - border.h)\n",
    "        # print(f'after: {item_y}', item.h)\n",
    "        # item_y = item_y + max_h\n",
    "        rects.append(Rectangle(x = item_x, y = item_y, w = item[1].shape[1], h = item[1].shape[0]))\n",
    "        # canvas.fill_rect(item_x, item_y, item.w, item.h)\n",
    "        add_transparent_image(background, item[1], item_x, item_y)\n",
    "        x_center = math.floor(((item_x + (item_x + item[1].shape[1])) / 2)) / background.shape[1]\n",
    "        y_center = math.floor((item_y + (item_y + item[1].shape[0])) / 2) / background.shape[0]\n",
    "        label.write(f'{item_names.index(item[0])} {x_center} {y_center} {item[1].shape[1] / background.shape[1]} {item[1].shape[0] / background.shape[0]}\\n')\n",
    "    labels.append(label)\n",
    "    # assert(overlap(rects) == False)\n",
    "    # assert(out_of_area(canvas, rects) == False)\n",
    "def generate_images(item_images, background_files):\n",
    "    generated_images = []\n",
    "    generated_labels = []\n",
    "    train_ratio = 0.70\n",
    "    validation_ratio = 0.20\n",
    "    test_ratio = 0.10\n",
    "    hash = hashlib.md5()\n",
    "    background_images = [(Path(name).stem, cv2.cvtColor(cv2.imread(name, cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB)) for name in background_files]\n",
    "    # for item_name, item_image in item_images:\n",
    "    for background_name, background_image in background_images:\n",
    "        background = background_image.copy()\n",
    "        try:\n",
    "            draw_items(background, generated_labels, random.sample(\n",
    "                item_images, randint(2, 5)), border=Border(10, 10))\n",
    "            generated_images.append(background)\n",
    "        except ValueError:\n",
    "            break\n",
    "\n",
    "    x_train, x_test = train_test_split(\n",
    "        list(zip(generated_images, generated_labels)), test_size=(1 - train_ratio))\n",
    "    x_val, x_test = train_test_split(\n",
    "        x_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "    for current_split, dataset in zip(['train', 'validate', 'test'], [x_train, x_val, x_test]):\n",
    "        for img, label in dataset:\n",
    "            # cv2.rectangle(img, (x_offset, y_offset), (x_offset + w, y_offset + h), (0,255,0), 2)\n",
    "            # imshow(img)\n",
    "            hash.update(repr(img).encode('utf-8'))\n",
    "            cv2.imwrite(\n",
    "                f'generated_images/{current_split}/images/{hash.hexdigest()}.png', cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "            with open(f'generated_images/{current_split}/labels/{hash.hexdigest()}.txt', 'w') as f:\n",
    "                print(label.getvalue(), file=f)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_names = [Path(name).stem for name in glob.glob('individual_items/*.png')]\n",
    "item_images = [(Path(name).stem, cv2.cvtColor(cv2.imread(name, cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGBA)) for name in glob.glob('individual_items/*.png')]\n",
    "background_files = np.random.choice(glob.glob('background_images/train/*.jpg'), size=500, replace=True)\n",
    "try:\n",
    "    shutil.rmtree('generated_images')\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    dirs = ['generated_images/train/images', 'generated_images/train/labels', 'generated_images/validate/images',\n",
    "            'generated_images/validate/labels', 'generated_images/test/images', 'generated_images/test/labels']\n",
    "    [os.makedirs(path, exist_ok=True) for path in dirs]\n",
    "\n",
    "for batch in grouper(background_files, 100):\n",
    "    generate_images(item_images, batch)\n",
    "\n",
    "with open('data.yaml', 'w') as f:\n",
    "    f.write(f'train: ../generated_images/train/images\\n')\n",
    "    f.write(f'val: ../generated_images/validate/images\\n')\n",
    "    f.write(f'nc: {len(item_names)}\\n')\n",
    "    f.write('names: [')\n",
    "    for name in item_names[:-1]:\n",
    "        f.write(f'\\'{name}\\',')\n",
    "    f.write(f'\\'{item_names[-1]}\\']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/train.py --weights yolov5s.pt --data data.yaml --batch 64 --img 640 --epochs 500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
